
We found that reinforcement learning improved race times more during the acquisition phase and performed better during retention than supervised (free-choice) learning. Both treatment groups chose better strategies during the sessions, with a clear 'win-stay, lose-switch' signature showing that they tended to stick to successful strategies. Despite the descriptively greater tendency for reinforcement learning to select better strategies and to have more pronounced "win-stay, lose-switch" tendencies during acquisition, these differences were not significantly different, nor were their contrasts at any of the sessions. However, we found that reinforcement learning had lower costs for suboptimally chosen strategies, indicating that the skiers had acquired a better cognitive understanding of the strategies' effect. However, this explanation does not comprehensively account for the disparity in race time. Compared with supervised (free choice) learning, reinforcement learning achieved greater improvement in the 'extend' strategy, suggesting that reinforcement feedback might have increased motor motivation. However, the reinforcement learning group did not outperform the supervised (target skill) learning group. This speaks to the importance of learning strategies. Interestingly, despite their clear difference in race time, the supervised (target skill) learning group did not significantly differ between the 'extend' and 'rock skis forward' strategies, suggesting the benefits of exposing learners to various strategies. Overall, we suggest that coaches can enhance skill learning by developing strategies and allowing learners to gain insights into their causal effects from evaluations instead of pure instruction.



A surprising finding was that the predicted probability of choosing the estimated best strategy decreased from free choice 2 to retention for reinforcement learning. At the same time, it increased for the supervised (free choice) learning group, leading to a significant interaction effect. This difference in change resulted in supervised learning (free choice) actually having a marginally higher predicted probability of choosing the estimated best strategy, contrary to our hypothesis. Nevertheless, we found that reinforcement learning skied better in retention and incurred lower costs (measured as regret) from their supoptimal chosen strategies compared to supervised (free choice) learning. One interpretation of this result is that skiers also took into account the risk associated with the execution of strategies, opting for those with lower risk. In that case, one might consider that "extend with rock skis forward" could be more exposed to risk since it could potentially make athletes lean to far backward to make the next turn.  However, this does not seem to be the case, as observed from both Figure 5a and the raw data in Figure 4, where the choices of this strategy have increased. Therefore, it appears that, at least on average, this is not a good account of our data. A more likely one is that that the skiers in reinforcement learning better grasped the effects of the different strategies and learned that some strategies were equally effective so that it did not matter much which they chose.

Our data can also be explained in a neuroeconomic framework \cite{pietro_mazzoni_why_2007, dudman_basal_2016}  by reinforcement learning increasing motor vigor. Executing repetitive up-and-down movements down a slalom course using the 'extend' and 'extend with rock skis forward' strategies is more energy expensive than performing the 'stand against' or 'rock skis forward' strategies. Besides having the energy to choose these strategies, it is possible that reinforcement learning had higher motor vigor when performing these strategies. That is, they performed the strategies with more power and quicker execution, which generally translates into better performance in ski racing given the snow resists the forces without being compressed. Previous studies on vigor have found that people make saccades \cite{takikawa_modulation_2002} and reach\cite{summerside_vigor_2018} faster towards targets paired with rewards than unpaired targets. It is therefore possible that the reinforcement learning increased motor vigor. Comments from several coaches, who watched the retention and transfer, from the sideline, was that the skiers in the reinforcement learning group tended to use more arm movements than skiers in the other groups, despite the instruction did not tell them to do that. The vigor perspective may also help explaining why reinforcement learning did not learn better than the supervised (target skill) learning group, as previous studies also have found that training with explicit knowledge boosts motor vigor much like the effect of reward itself \cite{anderson_rewards_2020, wong_explicit_2015}. It may therefore be that the getting information that one strategy was best from a current World Cup coach may have boosted the implicit motivation to perform this strategy well. 



, suggesting that strategy selection may have played an important role in learning. Interestingly, the supervised (target skill) learning group struggled to differentiate between the 'extend' and 'rock skis forward' strategies despite their clear race time difference, suggesting the benefits of exposing learners to various strategies. Exposing learners to different strategies might therefore be beneficial. Taken collectively, we suggest that coaches can enhance skill learning by developing strategies within their sport and allowing athletes to evaluate them, rather than always instructing learners.

Retention...

Our hypothesis was that reinforcement learning improves transfer to a new slalom course. The rationale for such expected behaviour was that reinforcement learning would achieve better insights into to the strategies' effect, thereby promoting better decision-making in new situations. However, we found no corroborating evidence for this hypothesis. This result aligns with studies that have observed enhanced retention but not transfer with reinforcement compared to supervised learning \cite{hasson_reinforcement_2015}. Furthermore, reinforcement learning has been found to yield a lower generalization signature in adaptive tasks \cite{lior_shmuelof_overcoming_2012}. One account for these findings is that reinforcement learning improves learning only for the specific situations in which one has been rewarded, as these are the instances in which learning has been reinforced. A potential mechanism for this is that training with rewards shortens the time window during which memory is unstable, affecting learners' capacity to extend learning to new situations \cite{robertson_memory_2018}. It is also conceivable that a more structured learning approach, where learners are exposed to frequent switches between strategies, is necessary to grasp the task's structure and promote transfer \cite{braun_structure_2010}. Future research should possibly investigate the effect of structural learning. 


